{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_weather_unsolved.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation"
      ],
      "metadata": {
        "id": "6iEY3BG_3O2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from random import shuffle\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class WeatherJenaDataset(Dataset):\n",
        "    MEAN = [ 9.88656343e+02,  9.10820659e+00,  2.83194958e+02,  4.59960541e+00,\n",
        "        7.59060084e+01,  1.33550981e+01,  9.35695962e+00,  3.99805597e+00,\n",
        "        5.91355033e+00,  9.46637099e+00,  1.21699436e+03, -5.94181630e-01,\n",
        "       -3.91512714e-01, -9.62158759e-01, -7.09400721e-01, -5.43022767e-05,\n",
        "       -7.24215306e-05,  5.28237873e-02, -1.62425716e-02]\n",
        "    STD = [ 8.29746565,  8.65494994,  8.72474584,  6.97227477, 16.55533649,\n",
        "        7.69473767,  4.20825963,  4.8177406 ,  2.67125215,  4.26005455,\n",
        "       40.95770444,  2.0129306 ,  1.56150746,  3.12732207,  2.61966312,\n",
        "        0.70709063,  0.70713733,  0.70062267,  0.71140285]\n",
        "\n",
        "    def download_dataset(self, root, download):\n",
        "        path = os.path.join(*[root, 'data.pkl'])\n",
        "        if not os.path.exists(path) and download:\n",
        "            # download dataset and import with pandas\n",
        "            url='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip'\n",
        "            print('Downloading dataset...')\n",
        "            filehandle, _ = urllib.request.urlretrieve(url)\n",
        "            zip_file_object = zipfile.ZipFile(filehandle, 'r')\n",
        "            first_file = zip_file_object.namelist()[0]\n",
        "            df = pd.read_csv(zip_file_object.open(first_file, 'r'))\n",
        "            df = self.prepare_dataset(df)\n",
        "            os.makedirs(root, exist_ok=True)\n",
        "            pd.to_pickle(df, path)\n",
        "            print('Download complete!')\n",
        "        else:\n",
        "            assert os.path.exists(path)\n",
        "            df = pd.read_pickle(path)\n",
        "            print('Files already downloaded and verified')\n",
        "        return df        \n",
        "\n",
        "    def prepare_dataset(self, df):\n",
        "        # subsample\n",
        "        print(df.shape, self.__dir__())\n",
        "        df = df.iloc[5::self.subsample_rate]\n",
        "        date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
        "        \n",
        "        # decompose wind speed\n",
        "        wv = df['wv (m/s)']\n",
        "        bad_wv = wv == -9999.0\n",
        "        wv.loc[bad_wv] = 0.0\n",
        "        max_wv = df['max. wv (m/s)']\n",
        "        bad_max_wv = max_wv == -9999.0\n",
        "        max_wv.loc[bad_max_wv] = 0.0\n",
        "        # df['wv (m/s)'].min()\n",
        "        wv = df.pop('wv (m/s)')\n",
        "        max_wv = df.pop('max. wv (m/s)')\n",
        "        wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "        df.loc['Wx'] = wv*np.cos(wd_rad)\n",
        "        df.loc['Wy'] = wv*np.sin(wd_rad)\n",
        "        df.loc['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "        df.loc['max Wy'] = max_wv*np.sin(wd_rad)\n",
        "\n",
        "        # decompose day/year signal\n",
        "        day = 24*60*60\n",
        "        year = (365.2425)*day\n",
        "        timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
        "        df.loc['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "        df.loc['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "        df.loc['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "        df.loc['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
        "\n",
        "        return df\n",
        "\n",
        "    def split_dataset(self, df, train):\n",
        "        n = len(df)\n",
        "        if train:\n",
        "            return df[0:int(n*0.7)]\n",
        "        else:\n",
        "            return df[int(n*0.7):]\n",
        "\n",
        "    def __init__(self, root, input_width=12, label_shift=2, train=True, download=True, subsample_rate=6):\n",
        "        super().__init__()\n",
        "        self.subsample_rate = subsample_rate\n",
        "        self.label_shift = label_shift\n",
        "        self.input_width = input_width\n",
        "        self.ds = self.split_dataset(self.download_dataset(root, download), train)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ds) - self.input_width - self.label_shift\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.ds.iloc[idx:idx+self.input_width].values\n",
        "        y = self.ds.iloc[idx+self.input_width+self.label_shift]['T (degC)'].astype('float32')\n",
        "        x = torch.tensor((x - np.array(self.MEAN)) / np.array(self.STD)).float()\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "tDeLG_842_JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WeatherJenaDataset('data', train=False).ds.head()"
      ],
      "metadata": {
        "id": "QecnkxJp_xaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yNtjWw9o8mM"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = WeatherJenaDataset('data')\n",
        "test_ds  = WeatherJenaDataset('data', train=False)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dl = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, \n",
        "                num_workers=0, drop_last=True, shuffle=True)\n",
        "test_dl  = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE, \n",
        "                num_workers=0, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n616vdx6r5_Y"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x, y) = iter(train_dl).next()\n",
        "plt.figure(figsize=(20,3))\n",
        "for i in range(len(x[::12])):\n",
        "    plt.plot(np.arange(len(x[i])) + i * 14, x[i][:, 1]*train_ds.STD[1] + train_ds.MEAN[1], c='blue', marker='o')\n",
        "    plt.scatter([13 + i * 14], [y[i]], color='red', marker='x')\n",
        "\n",
        "plt.ylabel('Temp')\n",
        "plt.xlabel('Timestep')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "DAcdUnX_zkPF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ORhiW8qeL3L"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class WeatherLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features_in: int, hidden_dim: int, \n",
        "                    num_features_out: int):\n",
        "\n",
        "        super().__init__()\n",
        "        # insert all the modules you need here\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        # define your forward pass here!\n",
        "        output = ...\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "iPgAf39Zzo8Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxJY61OrsqOY"
      },
      "source": [
        "def eval_mae(net: nn.Module, data_loader: torch.utils.data.DataLoader, \n",
        "             device: torch.device):\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(data_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "            # TODO compute the mae\n",
        "    \n",
        "    return ... # TODO return the MAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-saNxwGv8Ho"
      },
      "source": [
        "from torch.optim import SGD\n",
        "from datetime import datetime\n",
        "\n",
        "num_hidden      = 20\n",
        "num_epochs      = 3\n",
        "learning_rate   = 0.005\n",
        "num_features_in = 19\n",
        "num_features_out= 1\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ... # instantiate your model (and send it to the device)\n",
        "\n",
        "loss_fun = ... # what loss function are we gonna use here?\n",
        "opt = SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "now = datetime.now()\n",
        "  \n",
        "for e in tqdm(range(num_epochs)):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    train_err = ... # evaluate the error on the train set\n",
        "    test_err = ...  # evaluate the error on the test set\n",
        "\n",
        "    print(f'Epoch {e:03d} - Train MAE {train_err:.3f}\\tTest MAE {test_err:.3f}')\n",
        "\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_dl):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        # prepare for gradient computation\n",
        "\n",
        "        # perform forward step\n",
        "        \n",
        "        loss = ... # something\n",
        "        if i % 200 == 0:\n",
        "            print(f'loss {loss.cpu().item():.3f}')\n",
        "        \n",
        "        # perform backward step\n",
        "\n",
        "        # adjust weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect Results"
      ],
      "metadata": {
        "id": "3i_vtIVkzvnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(test_dl))\n",
        "y = data[1]\n",
        "y_pred = model(data[0].to(device)).cpu().detach()\n",
        "y, y_pred = y[:64], y_pred[:64]\n",
        "for i, (yi, yi_pred) in enumerate(zip(y, y_pred)):\n",
        "    plt.plot([i, i], [yi, yi_pred], color='red', alpha=.5, ls=\":\")\n",
        "plt.plot(np.arange(len(y)), y, marker='.', lw=0, color='k', label='ground truth')\n",
        "plt.plot(np.arange(len(y)), y_pred, marker='x', lw=0, color='red', label='guess')\n",
        "plt.xticks([])\n",
        "plt.ylabel('Temperature')\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "id": "CHvflayWwdAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}